<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>mcstatistics on mcstatistics</title>
    <link>/</link>
    <description>Recent content in mcstatistics on mcstatistics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Marlon Schumacher &amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Data Wrangling Part 1: Introduction to dplyr</title>
      <link>/post/data-wrangling-part-1-introduction-to-dplyr/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/data-wrangling-part-1-introduction-to-dplyr/</guid>
      <description>&lt;div id=&#34;introduction-to-dplyr&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction to dplyr&lt;/h1&gt;
&lt;p&gt;When it comes to data manipulation, &lt;code&gt;dplyr&lt;/code&gt; is a very powerful package with very intuitive functions. There are six important functions you will use often, if it comes to data manipulation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;filter()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;select()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mutate()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;arrange()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;group_by()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;summarise()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to these functions &lt;code&gt;dplyr&lt;/code&gt; offers you the ability to use the pipe-operator out of the &lt;code&gt;magrittr&lt;/code&gt; package. This operator is very useful and I highly recommend you to get used to it. Except these functions, &lt;code&gt;dplyr&lt;/code&gt; offers a lot more functions which are very useful. And, like always, you should look into the &lt;a href=&#34;https://cran.r-project.org/web/packages/dplyr/dplyr.pdf&#34;&gt;reference manual of dplyr&lt;/a&gt; for more details! I will mostly use the data frame &lt;code&gt;gapminder&lt;/code&gt; for explaining the functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;filter&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;filter()&lt;/h1&gt;
&lt;p&gt;In many cases you need to filter your dataset because you are only interested in specific cases or you want to exclude some cases. For that, the &lt;code&gt;filter()&lt;/code&gt; function provides an easy way to do that.&lt;/p&gt;
&lt;p&gt;Let’s take a look into the &lt;code&gt;gapminder&lt;/code&gt; df, which is an excerpt of the Gapminder data on life expectancy, GDP per capita, and population by country:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(gapminder)
head(gapminder)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
##   country     continent  year lifeExp      pop gdpPercap
##   &amp;lt;fct&amp;gt;       &amp;lt;fct&amp;gt;     &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 Afghanistan Asia       1952    28.8  8425333      779.
## 2 Afghanistan Asia       1957    30.3  9240934      821.
## 3 Afghanistan Asia       1962    32.0 10267083      853.
## 4 Afghanistan Asia       1967    34.0 11537966      836.
## 5 Afghanistan Asia       1972    36.1 13079460      740.
## 6 Afghanistan Asia       1977    38.4 14880372      786.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, different aspects of the data may be of interest:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;data for specific year(s)&lt;/li&gt;
&lt;li&gt;data for specific continent(s)&lt;/li&gt;
&lt;li&gt;data for specific continent(s) and year(s)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A very simple filtering could look like this one:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# filtering by the year 1997
gapminder %&amp;gt;% 
  filter(year == 1997) %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
##   country     continent  year lifeExp      pop gdpPercap
##   &amp;lt;fct&amp;gt;       &amp;lt;fct&amp;gt;     &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 Afghanistan Asia       1997    41.8 22227415      635.
## 2 Albania     Europe     1997    73.0  3428038     3193.
## 3 Algeria     Africa     1997    69.2 29072015     4797.
## 4 Angola      Africa     1997    41.0  9875024     2277.
## 5 Argentina   Americas   1997    73.3 36203463    10967.
## 6 Australia   Oceania    1997    78.8 18565243    26998.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is also possible to filter with more than one condition. If we are only interested in the year 1997 and the continent asia, we could use the following code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# filtering by the year 1997 and the continent asia
gapminder %&amp;gt;% 
  filter(year == 1997 &amp;amp; continent == &amp;quot;Asia&amp;quot;) %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
##   country          continent  year lifeExp        pop gdpPercap
##   &amp;lt;fct&amp;gt;            &amp;lt;fct&amp;gt;     &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;      &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 Afghanistan      Asia       1997    41.8   22227415      635.
## 2 Bahrain          Asia       1997    73.9     598561    20292.
## 3 Bangladesh       Asia       1997    59.4  123315288      973.
## 4 Cambodia         Asia       1997    56.5   11782962      734.
## 5 China            Asia       1997    70.4 1230075000     2289.
## 6 Hong Kong, China Asia       1997    80      6495918    28378.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can imagine, there are many logical operators that you can use. I guess, most of you know these operators already.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;&lt;/code&gt;: less than&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;=&lt;/code&gt;: less than or equal to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;==&lt;/code&gt;: equal to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;!=&lt;/code&gt;: not equal to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;gt;=&lt;/code&gt;: greater than or eqal to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;gt;&lt;/code&gt;: greater than&lt;/li&gt;
&lt;li&gt;&lt;code&gt;%in%&lt;/code&gt;: matching argument&lt;/li&gt;
&lt;li&gt;&lt;code&gt;!x&lt;/code&gt;: not x (e.g. often used for NA exclusion &lt;code&gt;!is.na(variable)&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following operators can be used to combine different conditions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;amp;&lt;/code&gt;: filtering by condition 1 &lt;strong&gt;and&lt;/strong&gt; contiditon 2&lt;/li&gt;
&lt;li&gt;&lt;code&gt;|&lt;/code&gt;: filtering by condition 1 &lt;strong&gt;or&lt;/strong&gt; condition 2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You will see a few of these operators in action later.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;select-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;select() function&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;select()&lt;/code&gt; function is a very simple one but can be useful, if the data frame is very large but you only need a few variables. You can select specific coloumns and you can also &lt;em&gt;delete&lt;/em&gt; sepcific coloumns.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# let&amp;#39;s select the coloumns country, continent, year and lifeExp
gapminder %&amp;gt;% 
  select(country, continent, year, lifeExp) %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
##   country     continent  year lifeExp
##   &amp;lt;fct&amp;gt;       &amp;lt;fct&amp;gt;     &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 Afghanistan Asia       1952    28.8
## 2 Afghanistan Asia       1957    30.3
## 3 Afghanistan Asia       1962    32.0
## 4 Afghanistan Asia       1967    34.0
## 5 Afghanistan Asia       1972    36.1
## 6 Afghanistan Asia       1977    38.4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# a shorter way to select these coloumns
gapminder %&amp;gt;% 
  select(country:lifeExp) %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
##   country     continent  year lifeExp
##   &amp;lt;fct&amp;gt;       &amp;lt;fct&amp;gt;     &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 Afghanistan Asia       1952    28.8
## 2 Afghanistan Asia       1957    30.3
## 3 Afghanistan Asia       1962    32.0
## 4 Afghanistan Asia       1967    34.0
## 5 Afghanistan Asia       1972    36.1
## 6 Afghanistan Asia       1977    38.4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we want to delete only a few columns of the df, we can do this by using &lt;code&gt;-&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# deleting the column population
gapminder %&amp;gt;% 
  select(-pop) %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
##   country     continent  year lifeExp gdpPercap
##   &amp;lt;fct&amp;gt;       &amp;lt;fct&amp;gt;     &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 Afghanistan Asia       1952    28.8      779.
## 2 Afghanistan Asia       1957    30.3      821.
## 3 Afghanistan Asia       1962    32.0      853.
## 4 Afghanistan Asia       1967    34.0      836.
## 5 Afghanistan Asia       1972    36.1      740.
## 6 Afghanistan Asia       1977    38.4      786.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mutate-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;mutate() function&lt;/h1&gt;
&lt;p&gt;You can create new columns with the &lt;code&gt;mutate()&lt;/code&gt; function. Moreover, it is possible to use the &lt;code&gt;mutate()&lt;/code&gt; function in combination with other functions (e.g. &lt;code&gt;case_when()&lt;/code&gt;). In the following code I create a new variable, where the value is 10% of the population size.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# creating a new coloumn where the value is 10% of the population
gapminder %&amp;gt;% 
  mutate(new_pop = round(pop*0.1)) %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##   country     continent  year lifeExp      pop gdpPercap new_pop
##   &amp;lt;fct&amp;gt;       &amp;lt;fct&amp;gt;     &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 Afghanistan Asia       1952    28.8  8425333      779.  842533
## 2 Afghanistan Asia       1957    30.3  9240934      821.  924093
## 3 Afghanistan Asia       1962    32.0 10267083      853. 1026708
## 4 Afghanistan Asia       1967    34.0 11537966      836. 1153797
## 5 Afghanistan Asia       1972    36.1 13079460      740. 1307946
## 6 Afghanistan Asia       1977    38.4 14880372      786. 1488037&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s create a new variable with three categories. Therefore, we will use the &lt;code&gt;mutate()&lt;/code&gt; function and the &lt;code&gt;case_when()&lt;/code&gt; function in combination. In the following example the new variable should include three categories: low life expectancy (lifeExp &amp;lt; 50), medium life expectancy (lifeExp &amp;gt;= 50 &amp;amp; &amp;lt;70) and high life expectancy (&amp;gt;= 70).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# creating three categories
gapminder %&amp;gt;% 
  mutate(lifeExp_cat = case_when(
    lifeExp &amp;lt; 50 ~ &amp;quot;low&amp;quot;,
    lifeExp &amp;lt; 70 &amp;amp; lifeExp &amp;gt;= 50 ~ &amp;quot;medium&amp;quot;, 
    lifeExp &amp;gt;= 70 ~ &amp;quot;high&amp;quot;
  )) %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##   country     continent  year lifeExp      pop gdpPercap lifeExp_cat
##   &amp;lt;fct&amp;gt;       &amp;lt;fct&amp;gt;     &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      
## 1 Afghanistan Asia       1952    28.8  8425333      779. low        
## 2 Afghanistan Asia       1957    30.3  9240934      821. low        
## 3 Afghanistan Asia       1962    32.0 10267083      853. low        
## 4 Afghanistan Asia       1967    34.0 11537966      836. low        
## 5 Afghanistan Asia       1972    36.1 13079460      740. low        
## 6 Afghanistan Asia       1977    38.4 14880372      786. low&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, you can add a bunch of conditions with the &lt;code&gt;case_when()&lt;/code&gt; function. Moreover, with this combination of these functions it is very easy to manipulate specific cases if it’s needed. Personally, I use the combination of these functions very often. In this way, it is very easy to implement specific encodings.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;group_by-summarise-function&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;group_by() &amp;amp; summarise() function&lt;/h1&gt;
&lt;p&gt;If you take a look into the data for the first time, it is often very useful to make some exploratory data analysis. The &lt;code&gt;group_by()&lt;/code&gt; function in combination with the &lt;code&gt;summarise()&lt;/code&gt; function makes it easy. For example, we can group by continent, calculate the mean for the life expectancy and plot the results for each continent over the time. I did that all with the pipe operator (&lt;code&gt;%&amp;gt;%&lt;/code&gt;). If you are unfamiliar with the use of this operator, you should familiarize yourself with it. In my opinion, you can work much more efficiently with it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
gapminder %&amp;gt;% 
  group_by(continent, year) %&amp;gt;% 
  summarise(mean_lifeExp = mean(lifeExp)) %&amp;gt;% 
  ggplot(aes(x = year, y = mean_lifeExp, col = continent)) +
    geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-11-10-data-wrangling-part-1-introduction-to-dplyr_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Structural Equation Modeling in R</title>
      <link>/post/structural-equation-modeling-in-r/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/structural-equation-modeling-in-r/</guid>
      <description>&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#lavaan-a-package-for-sem&#34;&gt;lavaan: A Package for SEM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#syntax-for-modelling&#34;&gt;Syntax for Modelling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-fitting&#34;&gt;Model Fitting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#standardized-estimated-parameter-change&#34;&gt;(Standardized) Estimated Parameter Change&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualization-plotting-sem&#34;&gt;Visualization: Plotting SEM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sampling-weights&#34;&gt;Sampling Weights&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;lavaan-a-package-for-sem&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;lavaan: A Package for SEM&lt;/h1&gt;
&lt;p align=&#34;justify&#34;&gt;
In my pervious post I made a &lt;a href=&#34;https://www.mcstatistics.eu/post/structural-equation-modeling-a-short-introduction/&#34;&gt;short introduction to Structural Equation Modeling (SEM)&lt;/a&gt;. But now it’s about using R for SEM. However, to use R for SEM we need the package &lt;code&gt;lavaan&lt;/code&gt; and I will introduce the basic functions of the package. For the visualization of the models we also need the package &lt;code&gt;semPlot&lt;/code&gt;. As you probably know already the installation of the packages is very simple:
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;lavaan&amp;quot;)
install.packages(&amp;quot;semPlot&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;syntax-for-modelling&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Syntax for Modelling&lt;/h1&gt;
&lt;p align=&#34;justify&#34;&gt;
The modely syntax of lavaan is used for specifying a SEM and is also very intuitive. There are three operators for model specification:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;=~&lt;/code&gt; is used to specify latent variables/factors&lt;/li&gt;
&lt;li&gt;&lt;code&gt;~~&lt;/code&gt; is used to specify (residual) (co)variances&lt;/li&gt;
&lt;li&gt;&lt;code&gt;~&lt;/code&gt; is used to specify rgeressions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An example model specification might look like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;example &amp;lt;- &amp;quot;
# measurement model
F1 =~ 1*V1 + V2 + V3
F2 =~ 1*V4 + V5 + V6

# (residual) (co)variances
V1 ~~ V1 # variance
V1 ~~ V3 # residual correlation

# regressions
F1 ~ F2&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model Fitting&lt;/h1&gt;
&lt;p align=&#34;justify&#34;&gt;
Now, let’s specify the first model. I will use an own dataset from a previous work. It’s also possible to use the built-in datasets &lt;code&gt;HolzingerSwineford1939&lt;/code&gt; or &lt;code&gt;PolitcialDemocracy&lt;/code&gt; from lavaan to become familiar with the package. Moreover, the functions &lt;code&gt;cfa()&lt;/code&gt; and &lt;code&gt;sem()&lt;/code&gt; are currently similar but they may differ in the future. It’s also possible to use one of the robust estimators, if you’re fitting the model.
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lavaan)
model &amp;lt;- &amp;quot;
# measurement model
F1 =~ 1*X1 + X2 + X3 + X4 + X5 + X6
F2 =~ 1*Y1 + Y2 + Y3 + Y4

# regression
F1 ~ F2&amp;quot;

# fitting the model
fit &amp;lt;- cfa(model, 
           data = data,
           estimator = &amp;quot;MLM&amp;quot;) # robust estimator 

# summary of the fit with standardized values and fit measurements
summary(fit, standardized = T, fit.measures = T)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## lavaan 0.6-3 ended normally after 39 iterations
## 
##   Optimization method                           NLMINB
##   Number of free parameters                         21
## 
##   Number of observations                          1914
## 
##   Estimator                                         ML      Robust
##   Model Fit Test Statistic                     218.644     204.758
##   Degrees of freedom                                34          34
##   P-value (Chi-square)                           0.000       0.000
##   Scaling correction factor                                  1.068
##     for the Satorra-Bentler correction
## 
## Model test baseline model:
## 
##   Minimum Function Test Statistic             4983.424    4648.582
##   Degrees of freedom                                45          45
##   P-value                                        0.000       0.000
## 
## User model versus baseline model:
## 
##   Comparative Fit Index (CFI)                    0.963       0.963
##   Tucker-Lewis Index (TLI)                       0.951       0.951
## 
##   Robust Comparative Fit Index (CFI)                         0.963
##   Robust Tucker-Lewis Index (TLI)                            0.951
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)             -39038.962  -39038.962
##   Loglikelihood unrestricted model (H1)     -38929.641  -38929.641
## 
##   Number of free parameters                         21          21
##   Akaike (AIC)                               78119.925   78119.925
##   Bayesian (BIC)                             78236.621   78236.621
##   Sample-size adjusted Bayesian (BIC)        78169.903   78169.903
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.053       0.051
##   90 Percent Confidence Interval          0.047  0.060       0.045  0.058
##   P-value RMSEA &amp;lt;= 0.05                          0.203       0.366
## 
##   Robust RMSEA                                               0.053
##   90 Percent Confidence Interval                             0.046  0.060
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.036       0.036
## 
## Parameter Estimates:
## 
##   Information                                 Expected
##   Information saturated (h1) model          Structured
##   Standard Errors                           Robust.sem
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&amp;gt;|z|)   Std.lv  Std.all
##   F1 =~                                                                 
##     X1                1.000                               1.197    0.652
##     X2                0.839    0.042   20.082    0.000    1.004    0.541
##     X3                0.857    0.040   21.283    0.000    1.026    0.679
##     X4                1.035    0.044   23.642    0.000    1.239    0.646
##     X5                0.884    0.042   20.917    0.000    1.058    0.621
##     X6                0.916    0.045   20.517    0.000    1.096    0.584
##   F2 =~                                                                 
##     Y1                1.000                               1.413    0.803
##     Y2                6.793    0.243   28.008    0.000    9.597    0.763
##     Y3                1.456    0.065   22.322    0.000    2.057    0.554
##     Y4                0.280    0.012   23.170    0.000    0.395    0.596
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&amp;gt;|z|)   Std.lv  Std.all
##   F1 ~                                                                  
##     F2               -0.228    0.024   -9.345    0.000   -0.270   -0.270
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&amp;gt;|z|)   Std.lv  Std.all
##    .X1                1.933    0.083   23.316    0.000    1.933    0.574
##    .X2                2.440    0.082   29.879    0.000    2.440    0.708
##    .X3                1.232    0.059   20.803    0.000    1.232    0.539
##    .X4                2.140    0.086   25.025    0.000    2.140    0.582
##    .X5                1.783    0.076   23.567    0.000    1.783    0.614
##    .X6                2.318    0.088   26.265    0.000    2.318    0.659
##    .Y1                1.101    0.072   15.382    0.000    1.101    0.355
##    .Y2               66.303    3.638   18.223    0.000   66.303    0.419
##    .Y3                9.577    0.369   25.929    0.000    9.577    0.694
##    .Y4                0.284    0.011   26.420    0.000    0.284    0.645
##    .F1                1.328    0.088   15.050    0.000    0.927    0.927
##     F2                1.996    0.093   21.441    0.000    1.000    1.000&lt;/code&gt;&lt;/pre&gt;
&lt;p align=&#34;justify&#34;&gt;
If you want to select specific fit measurements, you can use the function &lt;code&gt;fitmeasures()&lt;/code&gt;. By using the command &lt;code&gt;fit.measures = &amp;quot;all&amp;quot;&lt;/code&gt; you will get all available fit measures.
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fitmeasures(fit, fit.measures = c(&amp;quot;chisq&amp;quot;, &amp;quot;cfi&amp;quot;, &amp;quot;rmsea&amp;quot;, &amp;quot;srmr&amp;quot;)) %&amp;gt;% 
  kableExtra::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
x
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
chisq
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
218.64363505
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
cfi
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.96261082
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
rmsea
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.05326682
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
srmr
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.03600232
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p align=&#34;justify&#34;&gt;
Apart from the fit indices, the standardized residuals can also be used to interpret the model fit. Unfortunately there is no function to get the standardized residuals. However, a function can be written very fast for this. Using &lt;code&gt;cov2cor&lt;/code&gt; on the covariance matrices gives us the fitted and observed correlation matrices. To get the residual correlation matrix we need to subtracting the fitted correlation matrix from the observed correlation matrix.
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;std_residuals &amp;lt;- function(fit) {
  cov &amp;lt;- list(observed = inspect(fit, &amp;quot;sampstat&amp;quot;)$cov,
              fitted = fitted(fit)$cov)
  cor &amp;lt;- list(observed = cov2cor(cov$observed),
              fitted = cov2cor(cov$fitted))
  cor$residual &amp;lt;- cor$observed - cor$fitted
lapply(cor, function(x) round(x, 2))
}

std_residuals(fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $observed
##    X1    X2    X3    X4    X5    X6    Y1    Y2    Y3    Y4   
## X1  1.00                                                      
## X2  0.39  1.00                                                
## X3  0.43  0.44  1.00                                          
## X4  0.42  0.30  0.43  1.00                                    
## X5  0.38  0.30  0.42  0.42  1.00                              
## X6  0.41  0.28  0.35  0.43  0.38  1.00                        
## Y1 -0.13 -0.10 -0.18 -0.13 -0.18 -0.06  1.00                  
## Y2 -0.13 -0.09 -0.16 -0.13 -0.17 -0.08  0.63  1.00            
## Y3 -0.08 -0.08 -0.13 -0.05 -0.13  0.01  0.43  0.39  1.00      
## Y4 -0.12 -0.07 -0.13 -0.10 -0.18 -0.05  0.46  0.43  0.43  1.00
## 
## $fitted
##    X1    X2    X3    X4    X5    X6    Y1    Y2    Y3    Y4   
## X1  1.00                                                      
## X2  0.35  1.00                                                
## X3  0.44  0.37  1.00                                          
## X4  0.42  0.35  0.44  1.00                                    
## X5  0.41  0.34  0.42  0.40  1.00                              
## X6  0.38  0.32  0.40  0.38  0.36  1.00                        
## Y1 -0.14 -0.12 -0.15 -0.14 -0.13 -0.13  1.00                  
## Y2 -0.13 -0.11 -0.14 -0.13 -0.13 -0.12  0.61  1.00            
## Y3 -0.10 -0.08 -0.10 -0.10 -0.09 -0.09  0.44  0.42  1.00      
## Y4 -0.10 -0.09 -0.11 -0.10 -0.10 -0.09  0.48  0.45  0.33  1.00
## 
## $residual
##    X1    X2    X3    X4    X5    X6    Y1    Y2    Y3    Y4   
## X1  0.00                                                      
## X2  0.04  0.00                                                
## X3 -0.01  0.07  0.00                                          
## X4 -0.01 -0.05 -0.01  0.00                                    
## X5 -0.03 -0.04  0.00  0.02  0.00                              
## X6  0.03 -0.04 -0.05  0.05  0.02  0.00                        
## Y1  0.01  0.02 -0.03  0.01 -0.05  0.07  0.00                  
## Y2  0.01  0.03 -0.02  0.00 -0.04  0.04  0.02  0.00            
## Y3  0.01  0.00 -0.02  0.05 -0.04  0.10 -0.02 -0.03  0.00      
## Y4 -0.01  0.01 -0.03  0.00 -0.08  0.05 -0.02 -0.02  0.10  0.00&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;standardized-estimated-parameter-change&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;(Standardized) Estimated Parameter Change&lt;/h1&gt;
&lt;p align=&#34;justify&#34;&gt;
To identify potential model misspecification, you can use &lt;code&gt;modificationindices()&lt;/code&gt;. If the SEPC is &lt;span class=&#34;math inline&#34;&gt;\(\geq.20\)&lt;/span&gt;, there may be a possible misspecification. However, adjustments to the model should be based on a theoretical justification.
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# first 10 rows as output &amp;amp; sorting by mi-value
head(modificationindices(fit, sort. = T), 10) %&amp;gt;% 
  dplyr::select(-sepc.lv, -sepc.nox) %&amp;gt;% 
  kableExtra::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
lhs
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
op
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
rhs
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
mi
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
epc
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
sepc.all
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
78
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Y3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~~
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Y4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
59.82491
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3450967
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2091268
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
73
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Y1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~~
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Y2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
50.65517
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.9004680
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5736744
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
43
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
X2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~~
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
X3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
44.57299
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3354141
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1934529
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
33
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
=~
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
X6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21.73991
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1452641
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1094232
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
53
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
X3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~~
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
X6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.47615
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2289873
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1355164
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
59
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
X4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~~
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
X6
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.35185
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2900851
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1302539
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
44
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
X2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~~
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
X4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
20.23462
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.2881275
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1260850
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
32
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
F2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
=~
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
X5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
16.26564
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1121514
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0930021
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
75
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Y1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~~
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Y4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14.99285
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.0978666
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.1749505
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
71
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
X6
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
~~
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Y3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13.63301
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.4394287
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0932713
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;visualization-plotting-sem&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Visualization: Plotting SEM&lt;/h1&gt;
&lt;p align=&#34;justify&#34;&gt;
For visualization of an structural equation model the package &lt;code&gt;semPlot&lt;/code&gt; offers many possibilities. I would recommend you to look in the reference manual of this package. There are a lot of specifications you can do. However, the specification that I’m using should cover everything necessary for the beginning. In general, an adjustment of the rotation and the layout will probably be necessary.
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(semPlot)
semPaths(fit, # fitted model
         nCharNodes = 0, # no abbreviation in node labels
         whatLabels = &amp;quot;std&amp;quot;, # standardized parameter estimate 
         residuals = F, # excluding residuals and variances
         sizeLat = 10, # width latent
         sizeLat2 = 10, # height latent
         sizeMan = 6, # width manifest
         edge.label.cex = 0.90, # font size of parameters
         layout = &amp;quot;tree2&amp;quot;, # type of layout
         rotation = 2) # rotation of the layout&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-24-structural-equation-modeling-in-r_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you want to edit the label of the nodes, you can do this by using the &lt;code&gt;nodeLabels&lt;/code&gt; argument. To do so, the order of the nodes must first be determined.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# determine the order of the nodes 
semPaths(fit, # fitted model
         nCharNodes = 0, # no abbreviation in node labels
         whatLabels = &amp;quot;std&amp;quot;, # standardized parameter estimate 
         residuals = F, # excluding residuals and variances
         sizeLat = 10, # width latent
         sizeLat2 = 10, # height latent
         sizeMan = 6, # width manifest
         edge.label.cex = 0.90, # font size of parameters
         layout = &amp;quot;tree2&amp;quot;, # type of layout
         rotation = 2, # rotation of the layout
         nodeLabels = letters[1:12]) # getting the order of the nodes&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-24-structural-equation-modeling-in-r_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# labeling the nodes
semPaths(fit, # fitted model
         nCharNodes = 0, # no abbreviation in node labels
         whatLabels = &amp;quot;std&amp;quot;, # standardized parameter estimate 
         residuals = F, # excluding residuals and variances
         sizeLat = 10, # width latent
         sizeLat2 = 10, # height latent
         sizeMan = 6, # width manifest
         edge.label.cex = 0.90, # font size of parameters
         layout = &amp;quot;tree2&amp;quot;, # type of layout
         rotation = 2, # rotation of the layout
         nodeLabels = c(&amp;quot;var1&amp;quot;, &amp;quot;var2&amp;quot;, &amp;quot;var3&amp;quot;, &amp;quot;var4&amp;quot;, &amp;quot;var5&amp;quot;, &amp;quot;var6&amp;quot;,
                        &amp;quot;var7&amp;quot;, &amp;quot;var8&amp;quot;, &amp;quot;var9&amp;quot;, &amp;quot;var10&amp;quot;,
                        &amp;quot;Factor1&amp;quot;, &amp;quot;Factor2&amp;quot;)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-24-structural-equation-modeling-in-r_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
In addition, the following visualization is often used when it comes to using the function &lt;code&gt;semPaths()&lt;/code&gt;. There is a weighting of the edges depending on the standardized parameter estimates.
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;semPaths(fit, # fitted model
         nCharNodes = 0, # no abbreviation in node labels
         what = &amp;quot;std&amp;quot;, # standardized parameter estimates as weighted edges 
         whatLabels = &amp;quot;std&amp;quot;, # standardized parameter estimate 
         residuals = F, # excluding residuals and variances
         sizeLat = 10, # width latent
         sizeLat2 = 10, # height latent
         sizeMan = 6, # width manifest
         edge.label.cex = 0.90, # font size of parameters
         layout = &amp;quot;tree2&amp;quot;, # type of layout
         rotation = 2) # rotation of the layout&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-24-structural-equation-modeling-in-r_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sampling-weights&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Sampling Weights&lt;/h1&gt;
&lt;p align=&#34;justify&#34;&gt;
With lavaan version 0.6-3 there are two ways for weighting. On the one hand, you can use the package &lt;code&gt;lavaan.survey&lt;/code&gt;for taking sampling weights into account. On the other hand, it’s possible to specify the sampling weights within the &lt;code&gt;cfa()&lt;/code&gt; function.
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit_2 &amp;lt;- cfa(model, 
           data = data,
           estimator = &amp;quot;MLM&amp;quot;)

library(lavaan.survey)
# specify survey design
sd_fit &amp;lt;- survey::svydesign(id = ~1,
                  weights = ~weight,
                  data = data)

# fitting the model again while taking the survey design into account
surveyfit &amp;lt;- lavaan.survey(lavaan.fit = fit_2,
                           survey.design = sd_fit)

summary(surveyfit, standardized = T)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## lavaan 0.6-3 ended normally after 38 iterations
## 
##   Optimization method                           NLMINB
##   Number of free parameters                         31
## 
##   Number of observations                          1914
## 
##   Estimator                                         ML      Robust
##   Model Fit Test Statistic                     219.683     189.418
##   Degrees of freedom                                34          34
##   P-value (Chi-square)                           0.000       0.000
##   Scaling correction factor                                  1.160
##     for the Satorra-Bentler correction
## 
## Parameter Estimates:
## 
##   Information                                 Expected
##   Information saturated (h1) model          Structured
##   Standard Errors                           Robust.sem
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&amp;gt;|z|)   Std.lv  Std.all
##   F1 =~                                                                 
##     X1                1.000                               1.182    0.655
##     X2                0.869    0.043   20.161    0.000    1.027    0.554
##     X3                0.863    0.042   20.567    0.000    1.020    0.679
##     X4                1.044    0.046   22.914    0.000    1.234    0.647
##     X5                0.882    0.044   20.199    0.000    1.042    0.625
##     X6                0.914    0.047   19.551    0.000    1.080    0.579
##   F2 =~                                                                 
##     Y1                1.000                               1.409    0.799
##     Y2                6.841    0.261   26.160    0.000    9.636    0.763
##     Y3                1.477    0.069   21.527    0.000    2.080    0.556
##     Y4                0.280    0.013   22.094    0.000    0.394    0.599
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&amp;gt;|z|)   Std.lv  Std.all
##   F1 ~                                                                  
##     F2               -0.207    0.026   -8.079    0.000   -0.247   -0.247
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&amp;gt;|z|)   Std.lv  Std.all
##    .X1                3.567    0.043   83.354    0.000    3.567    1.977
##    .X2                3.948    0.044   88.923    0.000    3.948    2.131
##    .X3                2.508    0.036   69.819    0.000    2.508    1.669
##    .X4                3.387    0.046   74.218    0.000    3.387    1.776
##    .X5                2.785    0.039   70.605    0.000    2.785    1.671
##    .X6                3.205    0.045   71.777    0.000    3.205    1.717
##    .Y1                4.435    0.042  104.668    0.000    4.435    2.515
##    .Y2               45.500    0.303  149.930    0.000   45.500    3.604
##    .Y3               14.259    0.090  158.422    0.000   14.259    3.814
##    .Y4                2.888    0.016  184.040    0.000    2.888    4.390
##    .F1                0.000                               0.000    0.000
##     F2                0.000                               0.000    0.000
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&amp;gt;|z|)   Std.lv  Std.all
##    .X1                1.857    0.083   22.438    0.000    1.857    0.571
##    .X2                2.377    0.084   28.178    0.000    2.377    0.693
##    .X3                1.217    0.062   19.478    0.000    1.217    0.539
##    .X4                2.115    0.089   23.802    0.000    2.115    0.581
##    .X5                1.691    0.073   23.149    0.000    1.691    0.609
##    .X6                2.317    0.094   24.653    0.000    2.317    0.665
##    .Y1                1.126    0.078   14.497    0.000    1.126    0.362
##    .Y2               66.544    3.832   17.366    0.000   66.544    0.418
##    .Y3                9.653    0.382   25.275    0.000    9.653    0.690
##    .Y4                0.278    0.011   25.751    0.000    0.278    0.641
##    .F1                1.312    0.090   14.643    0.000    0.939    0.939
##     F2                1.984    0.100   19.911    0.000    1.000    1.000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# weighting within the cfa() function
weighted_fit &amp;lt;- cfa(model, 
           data = data,
           estimator = &amp;quot;MLM&amp;quot;,
           sampling.weights = &amp;quot;weight&amp;quot;) # sepcify sampling weights

summary(weighted_fit, standardized = T)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## lavaan 0.6-3 ended normally after 38 iterations
## 
##   Optimization method                           NLMINB
##   Number of free parameters                         21
## 
##   Number of observations                          1914
##   Sampling weights variable                     weight
## 
##   Estimator                                         ML      Robust
##   Model Fit Test Statistic                     219.683     191.128
##   Degrees of freedom                                34          34
##   P-value (Chi-square)                           0.000       0.000
##   Scaling correction factor                                  1.149
##     for the Yuan-Bentler correction (Mplus variant)
## 
## Parameter Estimates:
## 
##   Information                                 Observed
##   Observed information based on                Hessian
##   Standard Errors                   Robust.huber.white
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&amp;gt;|z|)   Std.lv  Std.all
##   F1 =~                                                                 
##     X1                1.000                               1.182    0.655
##     X2                0.869    0.042   20.621    0.000    1.027    0.554
##     X3                0.863    0.043   19.851    0.000    1.020    0.679
##     X4                1.044    0.047   22.353    0.000    1.234    0.647
##     X5                0.882    0.046   18.983    0.000    1.042    0.625
##     X6                0.914    0.047   19.579    0.000    1.080    0.579
##   F2 =~                                                                 
##     Y1                1.000                               1.409    0.799
##     Y2                6.841    0.236   29.036    0.000    9.636    0.763
##     Y3                1.477    0.072   20.498    0.000    2.080    0.556
##     Y4                0.280    0.013   21.018    0.000    0.394    0.599
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&amp;gt;|z|)   Std.lv  Std.all
##   F1 ~                                                                  
##     F2               -0.207    0.026   -8.011    0.000   -0.247   -0.247
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&amp;gt;|z|)   Std.lv  Std.all
##    .X1                1.857    0.084   22.175    0.000    1.857    0.571
##    .X2                2.377    0.086   27.532    0.000    2.377    0.693
##    .X3                1.217    0.063   19.245    0.000    1.217    0.539
##    .X4                2.115    0.091   23.330    0.000    2.115    0.581
##    .X5                1.691    0.074   22.828    0.000    1.691    0.609
##    .X6                2.317    0.096   24.170    0.000    2.317    0.665
##    .Y1                1.126    0.075   15.077    0.000    1.126    0.362
##    .Y2               66.544    3.654   18.210    0.000   66.544    0.418
##    .Y3                9.653    0.389   24.803    0.000    9.653    0.690
##    .Y4                0.278    0.011   25.036    0.000    0.278    0.641
##    .F1                1.312    0.092   14.338    0.000    0.939    0.939
##     F2                1.984    0.097   20.377    0.000    1.000    1.000&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Structural Equation Modeling: A Short Introduction</title>
      <link>/post/structural-equation-modeling-a-short-introduction/</link>
      <pubDate>Sat, 13 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/structural-equation-modeling-a-short-introduction/</guid>
      <description>&lt;div id=&#34;introduction-advantages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction &amp;amp; Advantages&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
There are a lot of variations regarding Structural Equation Modeling (SEM). Therefore, this article is focusing on the basics of SEM. Fundamentally, SEM can be classified as a combination of path analysis and confirmatory factor analysis. With SEM and path analysis you will have a big felxibility for specifying relationships between theoretical constructs. For example, it is possible to postulate rather complex models that may include a single construct that is theorized to be a predictor of some constructs and is also predicted by other constructs. You can estimate the multiple and interrelated dependence in a single analysis. Moreover, there are two types of variables which are used in SEM. Variables which are used only as a predictor are classified ad exogenous, whereas variables that are predicted by at least one other variable are classified as endogenous. But what are the exact benefits of SEM? Regarding this question, two main advantages of SEM will be discussed below.
&lt;/p&gt;
&lt;div id=&#34;latent-variables&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Latent Variables&lt;/h3&gt;
&lt;p align=&#34;justify&#34;&gt;
SEM distinguished between measurement and latent variables. One major difference between SEM and other methods is the use of latent variables which are captured by measurement variables. Latent variables represent constructs that can not be observed. For example, constructs such as &lt;em&gt;stability&lt;/em&gt;, &lt;em&gt;well-being&lt;/em&gt;, &lt;em&gt;statisfaction&lt;/em&gt; or &lt;em&gt;xenophobia&lt;/em&gt; are too complex to be measured directly. Moreover, with SEM the measruement error which cannot be explained by the latent variable will be considered. So, in a measurement model you will have a measurement error for each measurement variable. If &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt; is the latent variable and &lt;span class=&#34;math inline&#34;&gt;\(X1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(X2\)&lt;/span&gt; are the measurement variables and there is no measurement error, the path of &lt;span class=&#34;math inline&#34;&gt;\(F \rightarrow X1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(F \rightarrow X2\)&lt;/span&gt; would be &lt;span class=&#34;math inline&#34;&gt;\(1.0\)&lt;/span&gt;. But as we now, that will be not the case. So, assume a path of &lt;span class=&#34;math inline&#34;&gt;\(.7\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(F \rightarrow X1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(.8\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(F \rightarrow X2\)&lt;/span&gt;. Consequently, there would be a correlation of &lt;span class=&#34;math inline&#34;&gt;\(.56\)&lt;/span&gt; between the two variables &lt;span class=&#34;math inline&#34;&gt;\(X1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(X2\)&lt;/span&gt;. The measurement error will take into account the difference between &lt;span class=&#34;math inline&#34;&gt;\(1.0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(.56\)&lt;/span&gt;. Because of this, the relationships between the latent constructs can be more accurate.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simultaneous-estimation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Simultaneous Estimation&lt;/h3&gt;
&lt;p align=&#34;justify&#34;&gt;
Regarding most methods, only the relationship of a dependent variable to one or more independent variables can be estimated. However, using SEM, it is also possible to estimate the relationship between multiple dependent variables. But the simultaneous estimation gives another advantage. Thus, in addition to the direct effect, the indirect and total effects can be easily calculated. Just a small example:
&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-10-13-structural-equation-modeling-a-short-introduction_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\small Ind. \ Effect_{X1\rightarrow Y} = Dir. \ Effect_{X1\rightarrow X2}*Dir. \ Effect_{X2\rightarrow Y} = .9*-.47 = -.43\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\small Tot. \ Effect_{X1\rightarrow Y} = Ind. \ Effect_{X1\rightarrow Y} + Dir. \ Effect_{X1\rightarrow Y} = -.43 -.42 = -.85\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;identification&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Identification&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
Generally, a structural equation model must be identified, otherwise a clear parameter estimation can not be made. The identification should be determined for all model levels:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identification of the individual measurement models&lt;/li&gt;
&lt;li&gt;Identification of the structural model&lt;/li&gt;
&lt;li&gt;Identification of the overall model&lt;/li&gt;
&lt;/ul&gt;
&lt;p align=&#34;justify&#34;&gt;
The aim should be that there is over-identification at all model levels. In order to determine the degree of identification of a model, the following formula can be used (counting rule):
&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[t \leq\frac{p(p+1)}{2}\\
p = observed \ variables \\
t = estimated\ paramters\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The same formula can be used to calculate the degree of freedoms as well:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[df =\frac{p(p+1)}{2} - t\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Consequently, there are three scenarios for identification:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(df &amp;lt; 0\)&lt;/span&gt;: The model is underidentified&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(df = 0\)&lt;/span&gt;: The model is exactly identified&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(df &amp;gt; 0\)&lt;/span&gt;: The model is overidentified&lt;/li&gt;
&lt;/ul&gt;
&lt;p align=&#34;justify&#34;&gt;
As mentioned above, the goal should be an overidentified model. This is needed to perform further tests (for example: testing the fit of the model).
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-indices&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit Indices&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
At the beginning of SEM, testing the following null hypothesis was considered a good way to assess the model specification:
&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sum = \sum(0)\]&lt;/span&gt;&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Where &lt;span class=&#34;math inline&#34;&gt;\(\sum\)&lt;/span&gt; stands for the population covariance matrix and &lt;span class=&#34;math inline&#34;&gt;\(\sum{0}\)&lt;/span&gt; for the covariance matrix implied by the specified model. To check this null hypothesis, a &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt;-test can be used. However, this test is extremely sensitive to high sample sizes&lt;span class=&#34;citation&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;. For this reason, other methods have been developed to test the qualtiy of a model. In the following, some important Fit Indices will be discussed.
&lt;/p&gt;
&lt;div id=&#34;chi2-test&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt;-Test&lt;/h3&gt;
&lt;p align=&#34;justify&#34;&gt;
Despite the high sensitivity with high sample sizes, I would nevertheless explain the test briefly. The &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; is calculated as follows, where O represents the observations and E represents the expected values:
&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\chi^{2} = \sum_{i=1}^{n}\frac{(O_{i}-E_{i})^2}{E_{i}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Since the null hypothesis should not be rejected, the test should not be significant. If it comes to a significant result, then the model would have to be rejected or optimized. But as already pointed out, with larger sample size, there will always be a significant result. Based on this test, most models would have to be rejected. For that reason you should not rely on this test.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cfi---comparative-fit-index&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;CFI - Comparative Fit Index&lt;/h3&gt;
&lt;p align=&#34;justify&#34;&gt;
In contrast to the &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt;-test, the CFI takes into account the sample size and is reliable even for small samples:
&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[CFI = 1-\bigg(\frac{\lambda_{k}}{\lambda_{i}}\bigg) = 1 - \bigg(\frac{max[(\chi^2_{t}-df_{t}), 0]}{max[(\chi^2_{t}-df_{t}),(\chi^2_{n}-df_{n}),0]}\bigg)\]&lt;/span&gt;&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\chi^2_{t}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\chi^2_{n}\)&lt;/span&gt; are the &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; statistics for the target and the baseline model. The degree of freedoms of the target and the null model are represented by &lt;span class=&#34;math inline&#34;&gt;\(df_{t}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(df_{n}\)&lt;/span&gt;. However, the CFI evaluates the extent to which the tested model is superior to a alternative model in reproducing the observed covariance matrix. The range of the CFI is between &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;, whereas a value of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; indicates a perfect fit. The cut off value is &lt;span class=&#34;math inline&#34;&gt;\(.95\)&lt;/span&gt;&lt;span class=&#34;citation&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rmsea---root-mean-square-error-of-approximation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;RMSEA - Root Mean Square Error of Approximation&lt;/h3&gt;
&lt;p align=&#34;justify&#34;&gt;
RMSEA expresses the discrepancy between the observed covariance matrix and the covariance matrix implied by the model per degree of freedom:
&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[RMSEA = \sqrt\frac{\hat{F_{0}}}{df_{t}}=\sqrt\frac{max\Big[\frac{(\chi^2_{t}-df_{t})}{(N-1)},0\Big]}{df_{t}}= \sqrt\frac{\chi^2_{t} - df_{t}}{df_{t}(N-1)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
Where &lt;span class=&#34;math inline&#34;&gt;\(\chi^2_{t}\)&lt;/span&gt; is the &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; statistic and &lt;span class=&#34;math inline&#34;&gt;\(df_{t}\)&lt;/span&gt; the degree of freedom for the target model. In contrast to the CFI, the RMSEA does not perform well with small sample sizes. So, it tends to reject a true model, if the sample size is small. However, the RMSEA does include the model complexity. As with the CFI, there is a range from &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;, where a value of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implies a perfect fit. A value of &lt;span class=&#34;math inline&#34;&gt;\(\leq.05\)&lt;/span&gt; implies a very good fit, a value between &lt;span class=&#34;math inline&#34;&gt;\(.05\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(.08\)&lt;/span&gt; is considered with a good fit and a value between &lt;span class=&#34;math inline&#34;&gt;\(.08\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(.10\)&lt;/span&gt; represents a acceptable fit. However, if the RMSEA is greater than &lt;span class=&#34;math inline&#34;&gt;\(.10\)&lt;/span&gt; the fit of the model is bad&lt;span class=&#34;citation&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;srmr---standardized-root-mean-square-residual&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;SRMR - Standardized Root Mean Square Residual&lt;/h3&gt;
&lt;p align=&#34;justify&#34;&gt;
The SRMR is the root of the difference between the residuals of the covaruance matrix implied by the specified model and the&lt;span class=&#34;citation&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/span&gt;:
&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[SRMR = \sqrt{\frac{\Bigg\{2\sum_{i=1}^{p}\sum_{j=1}^{i}\Bigg[\frac{(s_{ij}-\hat\sigma_{ij})}{(s_{ii}*s_{jj})}\Bigg]^2\Bigg\}}{p(p+1)}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p align=&#34;justify&#34;&gt;
&lt;span class=&#34;math inline&#34;&gt;\(s_{ii}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(s_{jj}\)&lt;/span&gt; are the observed standard deviations. &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{ij}\)&lt;/span&gt; is the covariance matrix implied by the model, wheras &lt;span class=&#34;math inline&#34;&gt;\(s_{ij}\)&lt;/span&gt; is the observed covariance matrix. A value of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; implies a perfect fit. The SRMR should not be greater than &lt;span class=&#34;math inline&#34;&gt;\(.08\)&lt;/span&gt;&lt;span class=&#34;citation&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-optimization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model Optimization&lt;/h2&gt;
&lt;p align=&#34;justify&#34;&gt;
The modification indices can be used to identify potential model misspecification. If the standardized estimated parameter change (SEPC) is &lt;span class=&#34;math inline&#34;&gt;\(\geq.20\)&lt;/span&gt;, there may be a possible misspecification&lt;span class=&#34;citation&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/span&gt;. If you want to optimize the model, the parameters can be freely estimated, in which the SEPC is &lt;span class=&#34;math inline&#34;&gt;\(\geq.20\)&lt;/span&gt;. However, this quickly results in parameters being freely estimated where theoretical justification is only partially possible. Thus, error correlations are often freely estimated, which are theoretically rarely well justified&lt;span class=&#34;citation&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/span&gt;. The fit of the model can indeed be easily optimized in this way. But what brings a better fit, if the resulting model is no longer similar to the theory to be tested? Right, such a model offers little added value. Therefore, a model should only be optimized if this is theoretically well justified.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-cangur2015comparison&#34;&gt;
&lt;p&gt;&lt;span class=&#34;csl-baseline&#34;&gt;1&lt;/span&gt; Cangur, S. and Ercan, I. 2015: Comparison of model fit indices used in structural equation modeling under multivariate normality. &lt;em&gt;Journal of Modern Applied Statistical Methods&lt;/em&gt;. 14 (1), 14. &lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hu1999cutoff&#34;&gt;
&lt;p&gt;&lt;span class=&#34;csl-baseline&#34;&gt;2&lt;/span&gt; Hu, L.-t. and Bentler, P.M. 1999: Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives. &lt;em&gt;Structural Equation Modeling: A Multidisciplinary Journal&lt;/em&gt;. 6 (1), 1–55. &lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-chen2007sensitivity&#34;&gt;
&lt;p&gt;&lt;span class=&#34;csl-baseline&#34;&gt;3&lt;/span&gt; Chen, F.F. 2007: Sensitivity of goodness of fit indexes to lack of measurement invariance. &lt;em&gt;Structural Equation Modeling&lt;/em&gt;. 14 (3), 464–504. &lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-whittaker2012using&#34;&gt;
&lt;p&gt;&lt;span class=&#34;csl-baseline&#34;&gt;4&lt;/span&gt; Whittaker, T.A. 2012: Using the modification index and standardized expected parameter change for model modification. &lt;em&gt;The Journal of Experimental Education&lt;/em&gt;. 80 (1), 26–44. &lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hermida2015problem&#34;&gt;
&lt;p&gt;&lt;span class=&#34;csl-baseline&#34;&gt;5&lt;/span&gt; Hermida, R. 2015: The problem of allowing correlated errors in structural equation modeling: Concerns and considerations. &lt;em&gt;Computational Methods in Social Sciences&lt;/em&gt;. 3 (1), 5. &lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Example Page</title>
      <link>/tutorial/example/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 +0200</pubDate>
      
      <guid>/tutorial/example/</guid>
      <description>

&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;

&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
