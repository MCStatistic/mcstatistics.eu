---
title: "Structural Equation Modeling: A Short Introduction"
author: "Marlon Schumacher"
date: '2018-10-13'
slug: structural-equation-modeling-a-short-introduction
categories:
  - R
  - Tutorial
tags:
  - Structural Equation Modeling
  - SEM
  - fit indices
  - lavaan
  - semplot
bibliography: bibliography_001.bib 
csl: mcstatistics.csl
output: 
  blogdown::html_page:
    toc: false
---

## Introduction & Advantages
<p align="justify">There are a lot of variations regarding Structural Equation Modeling (SEM). Therefore, this article is focusing on the basics of SEM. Fundamentally, SEM can be classified as a combination of path analysis and confirmatory factor analysis. With SEM and path analysis you will have a big felxibility for specifying relationships between theoretical constructs. For example, it is possible to postulate rather complex models that may include a single construct that is theorized to be a predictor of some constructs and is also predicted by other constructs. You can estimate the multiple and interrelated dependence in a single analysis. Moreover, there are two types of variables which are used in SEM. Variables which are used only as a predictor are classified ad exogenous, whereas variables that are predicted by at least one other variable are classified as endogenous. But what are the exact benefits of SEM? Regarding this question, two main advantages of SEM will be discussed below.</p>

### Latent Variables
<p align="justify">SEM distinguished between measurement and latent variables. One major difference between SEM and other methods is the use of latent variables which are captured by measurement variables. Latent variables represent constructs that can not be observed. For example, constructs such as *stability*, *well-being*,  *statisfaction* or *xenophobia* are too complex to be measured directly. Moreover, with SEM the measruement error which cannot be explained by the latent variable will be considered. So, in a measurement model you will have a measurement error for each measurement variable. If $F$ is the latent variable and $X1$ and $X2$ are the measurement variables and there is no measurement error, the path of $F \rightarrow X1$ and $F \rightarrow X2$ would be 1.0. But as we now, that will be not the case. So, assume a path of .7 for $F \rightarrow X1$ and .8 for $F \rightarrow X2$. Consequently, there would be a correlation of .56 between the two variables $X1$ and $X2$. The measurement error will take into account the difference between 1.0 and .56. Because of this, the relationships between the latent constructs can be more accurate.</p>

### Simultaneous Estimation
<p align="justify">Regarding most methods, only the relationship of a dependent variable to one or more independent variables can be estimated. However, using SEM, it is also possible to estimate the relationship between multiple dependent variables. But the simultaneous estimation gives another advantage. Thus, in addition to the direct effect, the indirect and total effects can be easily calculated. Just a small example:</p>

```{r echo=FALSE, message=FALSE, warning=FALSE, fig_width= 6, fig_height = 2}
library(lavaan)
model <- "
mpg ~ cyl + disp
cyl ~ disp"

fit <- cfa(model = model,
           data = mtcars,
           estimator = "MLM")

library(semPlot)
semPaths(fit,
         whatLabels = "std",
         edge.label.cex=1,
         residuals=FALSE,
         sizeMan = 8,
         layout = "spring",
         rotation = 1,
         sizeInt= 7,
         nodeLabels = c("Y", "X2", "X1"))
```
   
$\small Ind. \ Effect_{X1\rightarrow Y} = Dir. \ Effect_{X1\rightarrow X2}*Dir. \ Effect_{X2\rightarrow Y} = .9*-.47 = -.43$ 
$\small Tot. \ Effect_{X1\rightarrow Y} = Ind. \ Effect_{X1\rightarrow Y} + Dir. \ Effect_{X1\rightarrow Y} = -.43 -.42 = -.85$

## Identification
<p align="justify">Generally, a structural equation model must be identified, otherwise a clear parameter estimation can not be made. The identification should be determined for all model levels:</p>

+ Identification of the individual measurement models
+ Identification of the structural model
+ Identification of the overall model

<p align="justify">The aim should be that there is over-identification at all model levels. In order to determine the degree of identification of a model, the following formula can be used (counting rule):</p> 

$$t \leq\frac{p(p+1)}{2}\\
p = observed \ variables \\
t = estimated\ paramters$$

The same formula can be used to calculate the degrees of freedom as well:

$$df =\frac{p(p+1)}{2} - t$$

Consequently, there are three scenarios for identification:

+ $df < 0$: The model is underidentified
+ $df = 0$: The model is exactly identified 
+ $df > 0$: The model is overidentified

<p align="justify">As mentioned above, the goal should be an overidentified model. This is needed to perform further tests (for example: testing the fit of the model).</p>

## Fit Indices
<p align="justify">At the beginning of SEM, testing the following null hypothesis was considered a good way to assess the model specification:</p>

$$\sum = \sum(0)$$

<p align="justify">Where $\sum$ stands for the population covariance matrix and $\sum{0}$ for the covariance matrix implied by the specified model. To check this null hypothesis, a $\chi^2$-test can be used. However, this test is extremely sensitive to high sample sizes [@cangur2015comparison]. For this reason, other methods have been developed to test the qualtiy of a model. In the following, some important Fit Indices will be discussed.</p>

### $\chi^2$-Test
<p align="justify">Despite the high sensitivity with high case numbers, I would nevertheless explain the test briefly. The $\chi^2$ is calculated as follows, where O represents the observations and E represents the expected values:</p>

$$\chi^{2} = \sum_{i=1}^{n}\frac{(O_{i}-E_{i})^2}{E_{i}}$$

<p align="justify">Since the null hypothesis should not be rejected, the test should not be significant. If it comes to a significant result, then the model would have to be rejected or optimized. But as already pointed out, with larger sample size, there will always be a significant result. Based on this test, most models would have to be rejected. For that reason you should not rely on this test.</p>

### CFI - Comparative Fit Index
<p align="justify">In contrast to the $\chi^2$-test, the CFI takes into account the sample size and is reliable even for small samples:</p>

$$CFI = 1-\bigg(\frac{\lambda_{k}}{\lambda_{i}}\bigg) = 1 - \bigg(\frac{max[(\chi^2_{t}-df_{t}), 0]}{max[(\chi^2_{t}-df_{t}),(\chi^2_{n}-df_{n}),0]}\bigg)$$

<p align="justify">$\chi^2_{t}$ and $\chi^2_{n}$ are the  $\chi^2$ statistics for the target and the baseline model. The degrees of freedom of the target and the null model are represented by $df_{t}$ and $df_{n}$. However, the CFI evaluates the extent to which the tested model is superior to a alternative model in reproducing the observed covariance matrix. The range of the CFI is between $0$ and $1$, whereas a value of $1$ indicates a perfect fit. The cut off value is $.95$ [@hu1999cutoff].</p>

### RMSEA - Root Mean Square Error of Approximation
<p align="justify">RMSEA expresses the discrepancy between the observed covariance matrix and the covariance matrix implied by the model per degree of freedom:</p>

$$RMSEA = \sqrt\frac{\hat{F_{0}}}{df_{t}}=\sqrt\frac{max\Big[\frac{(\chi^2_{t}-df_{t})}{(N-1)},0\Big]}{df_{t}}= \sqrt\frac{\chi^2_{t} - df_{t}}{df_{t}(N-1)}$$

<p align="justify">Where $\chi^2_{t}$ is the $\chi^2$ statistic and $df_{t}$ the degree of freedom for the target model. In contrast to the CFI, the RMSEA does not perform well with small sample sizes. So, it tends to reject a true model, if the sample size is small. However, the RMSEA does include the model complexity (Cangur/Ercan 2015: 157). As with the CFI, there is a range from $0$ to $1$, where a value of $0$ implies a perfect fit. A value of $\leq.05$ implies a very good fit, a value between $.05$ and $.08$ is considered with a good fit and a value between $.08$ and $.10$ represents a acceptable fit. However, if the RMSEA is greater than $.10$ the fit of the model is bad [@hu1999cutoff].</p>

### SRMR - Standardized Root Mean Square Residual
<p align="justify">The SRMR is the root of the difference between the residuals of the covaruance matrix implied by the specified model and the [@chen2007sensitivity]:</p>

$$SRMR = \sqrt{\frac{\Bigg\{2\sum_{i=1}^{p}\sum_{j=1}^{i}\Bigg[\frac{(s_{ij}-\hat\sigma_{ij})}{(s_{ii}*s_{jj})}\Bigg]^2\Bigg\}}{p(p+1)}}$$

<p align="justify">$s_{ii}$ and $s_{jj}$ are the observed standard deviations. $\sigma_{ij}$ is the covariance matrix implied by the model, wheras $s_{ij}$ is the observed covariance matrix. A value of $0$ implies a perfect fit. The SRMR should not be greater than $.08$ [@hu1999cutoff].</p>

## Model Optimization
<p align="justify">The modification indices can be used to identify potential model misspecification. If the standardized estimated parameter change (SEPC) is $\geq.20$, there may be a possible misspecification [@whittaker2012using]. If you want to optimize the model, the parameters can be freely estimated, in which the SEPC is $\geq.20$. However, this quickly results in parameters being freely estimated where theoretical justification is only partially possible. Thus, error correlations are often freely estimated, which are theoretically rarely well justified [@hermida2015problem]. The fit of the model can indeed be easily optimized in this way. But what brings a better fit, if the resulting model is no longer similar to the theory to be tested? Right, such a model offers little added value. Therefore, a model should only be optimized if this is theoretically well justified.</p>

##References