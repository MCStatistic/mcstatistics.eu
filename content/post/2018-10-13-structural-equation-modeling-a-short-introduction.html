---
title: "Structural Equation Modeling: A Short Introduction"
author: "Marlon Schumacher"
date: '2018-10-13'
slug: structural-equation-modeling-a-short-introduction
categories:
  - R
  - Tutorial
tags:
  - Structural Equation Modeling
  - SEM
  - fit indices
  - lavaan
  - semplot
bibliography: bibliography_001.bib 
csl: mcstatistics.csl
output: 
  blogdown::html_page:
    toc: false
---



<div id="introduction-advantages" class="section level2">
<h2>Introduction &amp; Advantages</h2>
<p align="justify">
There are a lot of variations regarding Structural Equation Modeling (SEM). Therefore, this article is focusing on the basics of SEM. Fundamentally, SEM can be classified as a combination of path analysis and confirmatory factor analysis. With SEM and path analysis you will have a big felxibility for specifying relationships between theoretical constructs. For example, it is possible to postulate rather complex models that may include a single construct that is theorized to be a predictor of some constructs and is also predicted by other constructs. You can estimate the multiple and interrelated dependence in a single analysis. Moreover, there are two types of variables which are used in SEM. Variables which are used only as a predictor are classified ad exogenous, whereas variables that are predicted by at least one other variable are classified as endogenous. But what are the exact benefits of SEM? Regarding this question, two main advantages of SEM will be discussed below.
</p>
<div id="latent-variables" class="section level3">
<h3>Latent Variables</h3>
<p align="justify">
SEM distinguished between measurement and latent variables. One major difference between SEM and other methods is the use of latent variables which are captured by measurement variables. Latent variables represent constructs that can not be observed. For example, constructs such as <em>stability</em>, <em>well-being</em>, <em>statisfaction</em> or <em>xenophobia</em> are too complex to be measured directly. Moreover, with SEM the measruement error which cannot be explained by the latent variable will be considered. So, in a measurement model you will have a measurement error for each measurement variable. If <span class="math inline">\(F\)</span> is the latent variable and <span class="math inline">\(X1\)</span> and <span class="math inline">\(X2\)</span> are the measurement variables and there is no measurement error, the path of <span class="math inline">\(F \rightarrow X1\)</span> and <span class="math inline">\(F \rightarrow X2\)</span> would be 1.0. But as we now, that will be not the case. So, assume a path of .7 for <span class="math inline">\(F \rightarrow X1\)</span> and .8 for <span class="math inline">\(F \rightarrow X2\)</span>. Consequently, there would be a correlation of .56 between the two variables <span class="math inline">\(X1\)</span> and <span class="math inline">\(X2\)</span>. The measurement error will take into account the difference between 1.0 and .56. Because of this, the relationships between the latent constructs can be more accurate.
</p>
</div>
<div id="simultaneous-estimation" class="section level3">
<h3>Simultaneous Estimation</h3>
<p align="justify">
Regarding most methods, only the relationship of a dependent variable to one or more independent variables can be estimated. However, using SEM, it is also possible to estimate the relationship between multiple dependent variables. But the simultaneous estimation gives another advantage. Thus, in addition to the direct effect, the indirect and total effects can be easily calculated. Just a small example:
</p>
<p><img src="/post/2018-10-13-structural-equation-modeling-a-short-introduction_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p><span class="math inline">\(\small Ind. \ Effect_{X1\rightarrow Y} = Dir. \ Effect_{X1\rightarrow X2}*Dir. \ Effect_{X2\rightarrow Y} = .9*-.47 = -.43\)</span> <span class="math inline">\(\small Tot. \ Effect_{X1\rightarrow Y} = Ind. \ Effect_{X1\rightarrow Y} + Dir. \ Effect_{X1\rightarrow Y} = -.43 -.42 = -.85\)</span></p>
</div>
</div>
<div id="identification" class="section level2">
<h2>Identification</h2>
<p align="justify">
Generally, a structural equation model must be identified, otherwise a clear parameter estimation can not be made. The identification should be determined for all model levels:
</p>
<ul>
<li>Identification of the individual measurement models</li>
<li>Identification of the structural model</li>
<li>Identification of the overall model</li>
</ul>
<p align="justify">
The aim should be that there is over-identification at all model levels. In order to determine the degree of identification of a model, the following formula can be used (counting rule):
</p>
<p><span class="math display">\[t \leq\frac{p(p+1)}{2}\\
p = observed \ variables \\
t = estimated\ paramters\]</span></p>
<p>The same formula can be used to calculate the degrees of freedom as well:</p>
<p><span class="math display">\[df =\frac{p(p+1)}{2} - t\]</span></p>
<p>Consequently, there are three scenarios for identification:</p>
<ul>
<li><span class="math inline">\(df &lt; 0\)</span>: The model is underidentified</li>
<li><span class="math inline">\(df = 0\)</span>: The model is exactly identified</li>
<li><span class="math inline">\(df &gt; 0\)</span>: The model is overidentified</li>
</ul>
<p align="justify">
As mentioned above, the goal should be an overidentified model. This is needed to perform further tests (for example: testing the fit of the model).
</p>
</div>
<div id="fit-indices" class="section level2">
<h2>Fit Indices</h2>
<p align="justify">
At the beginning of SEM, testing the following null hypothesis was considered a good way to assess the model specification:
</p>
<p><span class="math display">\[\sum = \sum(0)\]</span></p>
<p align="justify">
Where <span class="math inline">\(\sum\)</span> stands for the population covariance matrix and <span class="math inline">\(\sum{0}\)</span> for the covariance matrix implied by the specified model. To check this null hypothesis, a <span class="math inline">\(\chi^2\)</span>-test can be used. However, this test is extremely sensitive to high sample sizes<span class="citation"><sup>1</sup></span>. For this reason, other methods have been developed to test the qualtiy of a model. In the following, some important Fit Indices will be discussed.
</p>
<div id="chi2-test" class="section level3">
<h3><span class="math inline">\(\chi^2\)</span>-Test</h3>
<p align="justify">
Despite the high sensitivity with high case numbers, I would nevertheless explain the test briefly. The <span class="math inline">\(\chi^2\)</span> is calculated as follows, where O represents the observations and E represents the expected values:
</p>
<p><span class="math display">\[\chi^{2} = \sum_{i=1}^{n}\frac{(O_{i}-E_{i})^2}{E_{i}}\]</span></p>
<p align="justify">
Since the null hypothesis should not be rejected, the test should not be significant. If it comes to a significant result, then the model would have to be rejected or optimized. But as already pointed out, with larger sample size, there will always be a significant result. Based on this test, most models would have to be rejected. For that reason you should not rely on this test.
</p>
</div>
<div id="cfi---comparative-fit-index" class="section level3">
<h3>CFI - Comparative Fit Index</h3>
<p align="justify">
In contrast to the <span class="math inline">\(\chi^2\)</span>-test, the CFI takes into account the sample size and is reliable even for small samples:
</p>
<p><span class="math display">\[CFI = 1-\bigg(\frac{\lambda_{k}}{\lambda_{i}}\bigg) = 1 - \bigg(\frac{max[(\chi^2_{t}-df_{t}), 0]}{max[(\chi^2_{t}-df_{t}),(\chi^2_{n}-df_{n}),0]}\bigg)\]</span></p>
<p align="justify">
<span class="math inline">\(\chi^2_{t}\)</span> and <span class="math inline">\(\chi^2_{n}\)</span> are the <span class="math inline">\(\chi^2\)</span> statistics for the target and the baseline model. The degrees of freedom of the target and the null model are represented by <span class="math inline">\(df_{t}\)</span> and <span class="math inline">\(df_{n}\)</span>. However, the CFI evaluates the extent to which the tested model is superior to a alternative model in reproducing the observed covariance matrix. The range of the CFI is between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>, whereas a value of <span class="math inline">\(1\)</span> indicates a perfect fit. The cut off value is <span class="math inline">\(.95\)</span><span class="citation"><sup>2</sup></span>.
</p>
</div>
<div id="rmsea---root-mean-square-error-of-approximation" class="section level3">
<h3>RMSEA - Root Mean Square Error of Approximation</h3>
<p align="justify">
RMSEA expresses the discrepancy between the observed covariance matrix and the covariance matrix implied by the model per degree of freedom:
</p>
<p><span class="math display">\[RMSEA = \sqrt\frac{\hat{F_{0}}}{df_{t}}=\sqrt\frac{max\Big[\frac{(\chi^2_{t}-df_{t})}{(N-1)},0\Big]}{df_{t}}= \sqrt\frac{\chi^2_{t} - df_{t}}{df_{t}(N-1)}\]</span></p>
<p align="justify">
Where <span class="math inline">\(\chi^2_{t}\)</span> is the <span class="math inline">\(\chi^2\)</span> statistic and <span class="math inline">\(df_{t}\)</span> the degree of freedom for the target model. In contrast to the CFI, the RMSEA does not perform well with small sample sizes. So, it tends to reject a true model, if the sample size is small. However, the RMSEA does include the model complexity (Cangur/Ercan 2015: 157). As with the CFI, there is a range from <span class="math inline">\(0\)</span> to <span class="math inline">\(1\)</span>, where a value of <span class="math inline">\(0\)</span> implies a perfect fit. A value of <span class="math inline">\(\leq.05\)</span> implies a very good fit, a value between <span class="math inline">\(.05\)</span> and <span class="math inline">\(.08\)</span> is considered with a good fit and a value between <span class="math inline">\(.08\)</span> and <span class="math inline">\(.10\)</span> represents a acceptable fit. However, if the RMSEA is greater than <span class="math inline">\(.10\)</span> the fit of the model is bad<span class="citation"><sup>2</sup></span>.
</p>
</div>
<div id="srmr---standardized-root-mean-square-residual" class="section level3">
<h3>SRMR - Standardized Root Mean Square Residual</h3>
<p align="justify">
The SRMR is the root of the difference between the residuals of the covaruance matrix implied by the specified model and the<span class="citation"><sup>3</sup></span>:
</p>
<p><span class="math display">\[SRMR = \sqrt{\frac{\Bigg\{2\sum_{i=1}^{p}\sum_{j=1}^{i}\Bigg[\frac{(s_{ij}-\hat\sigma_{ij})}{(s_{ii}*s_{jj})}\Bigg]^2\Bigg\}}{p(p+1)}}\]</span></p>
<p align="justify">
<span class="math inline">\(s_{ii}\)</span> and <span class="math inline">\(s_{jj}\)</span> are the observed standard deviations. <span class="math inline">\(\sigma_{ij}\)</span> is the covariance matrix implied by the model, wheras <span class="math inline">\(s_{ij}\)</span> is the observed covariance matrix. A value of <span class="math inline">\(0\)</span> implies a perfect fit. The SRMR should not be greater than <span class="math inline">\(.08\)</span><span class="citation"><sup>2</sup></span>.
</p>
</div>
</div>
<div id="model-optimization" class="section level2">
<h2>Model Optimization</h2>
<p align="justify">
The modification indices can be used to identify potential model misspecification. If the standardized estimated parameter change (SEPC) is <span class="math inline">\(\geq.20\)</span>, there may be a possible misspecification<span class="citation"><sup>4</sup></span>. If you want to optimize the model, the parameters can be freely estimated, in which the SEPC is <span class="math inline">\(\geq.20\)</span>. However, this quickly results in parameters being freely estimated where theoretical justification is only partially possible. Thus, error correlations are often freely estimated, which are theoretically rarely well justified<span class="citation"><sup>5</sup></span>. The fit of the model can indeed be easily optimized in this way. But what brings a better fit, if the resulting model is no longer similar to the theory to be tested? Right, such a model offers little added value. Therefore, a model should only be optimized if this is theoretically well justified.
</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-cangur2015comparison">
<p><span class="csl-baseline">1</span> Cangur, S. and Ercan, I. 2015: Comparison of model fit indices used in structural equation modeling under multivariate normality. <em>Journal of Modern Applied Statistical Methods</em>. 14 (1), 14. </p>
</div>
<div id="ref-hu1999cutoff">
<p><span class="csl-baseline">2</span> Hu, L.-t. and Bentler, P.M. 1999: Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives. <em>Structural Equation Modeling: A Multidisciplinary Journal</em>. 6 (1), 1–55. </p>
</div>
<div id="ref-chen2007sensitivity">
<p><span class="csl-baseline">3</span> Chen, F.F. 2007: Sensitivity of goodness of fit indexes to lack of measurement invariance. <em>Structural Equation Modeling</em>. 14 (3), 464–504. </p>
</div>
<div id="ref-whittaker2012using">
<p><span class="csl-baseline">4</span> Whittaker, T.A. 2012: Using the modification index and standardized expected parameter change for model modification. <em>The Journal of Experimental Education</em>. 80 (1), 26–44. </p>
</div>
<div id="ref-hermida2015problem">
<p><span class="csl-baseline">5</span> Hermida, R. 2015: The problem of allowing correlated errors in structural equation modeling: Concerns and considerations. <em>Computational Methods in Social Sciences</em>. 3 (1), 5. </p>
</div>
</div>
</div>
